{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n# import researchpy as rp\nimport scipy.stats as stats\nimport statsmodels.api as sm\n\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, cross_val_predict, train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report,accuracy_score \nimport itertools\n\n# % matplotlib inline\n\naccepted = pd.read_csv(\n    '../input/lending-club/accepted_2007_to_2018q4.csv/accepted_2007_to_2018Q4.csv',\n    parse_dates=['issue_d'], infer_datetime_format=True)\naccepted = accepted[(accepted.issue_d >= '2017-01-01 00:00:00') & (accepted.issue_d < '2019-01-01 00:00:00')]\naccepted = accepted.reset_index(drop=True)\naccepted.head() \ndf2=accepted[['funded_amnt','emp_length','zip_code','addr_state','dti','fico_range_high','purpose']]\ndf2.columns = ['Amount Requested', 'Employment Length', 'Zip Code', 'State', 'Debt-To-Income Ratio','Risk_Score','purpose']\ndf2=df2.drop(['purpose'], axis = 1) \ndf2['accepted']=1","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rejected = pd.read_csv(\n    '../input/lending-club/rejected_2007_to_2018q4.csv/rejected_2007_to_2018Q4.csv')\n# rejected = rejected[(rejected.issue_d >= '2017-01-01 00:00:00') & (rejected.issue_d < '2019-01-01 00:00:00')]\n# rejected = rejected.reset_index(drop=True)\nrejected.head() \nrejected=rejected.drop(['Loan Title'], axis = 1) \nrejected=rejected.drop(['Application Date'], axis = 1) \nrejected=rejected.drop(['Policy Code'], axis = 1) \ndf1=rejected[['Amount Requested', 'Employment Length', 'Zip Code', 'State', 'Debt-To-Income Ratio','Risk_Score']]\ndf1['accepted']=0","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  # Remove the CWD from sys.path while we load stuff.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([df1,df2],ignore_index=True)\ndf['Debt-To-Income Ratio']=df['Debt-To-Income Ratio'].astype(str).map(lambda x: x.rstrip('%'))\ndf['Debt-To-Income Ratio']=df['Debt-To-Income Ratio'].astype(float)\ndf = df[df['Employment Length'].notna()]\ndf=df.drop(['Zip Code'], axis = 1) \ndf = df.dropna(how='any',axis=0)\n\n\n# q = df[\"Amount Requested\"].quantile(0.99)\n# df=df[df[\"Amount Requested\"] < q]\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Determine Numeric & Categorical Columns\nnumeric=df.columns[df.dtypes==\"float64\"]\ncat=df.columns[df.dtypes==\"object\"]\n\n#Normalize numeric columns and create dummy variables with categorical columns\n\nscaler=StandardScaler()\ndf[numeric] = scaler.fit_transform(df[numeric])\ndf=pd.get_dummies(df,drop_first=True)\nX = df.drop('accepted', axis=1)\ny = df['accepted']\nX_train, X_test, y_train, y_test = train_test_split(X, y)\n\n","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#TensorFlow Model \n\n\nimport tensorflow.compat.v1 as tf\nfrom tensorflow.python.framework import ops\ntf.compat.v1.disable_eager_execution()\nimport numpy as np\n\n# Reset the graph for Tensorboard\ndef reset_graph(seed=42):\n    tf.reset_default_graph()\n    tf.set_random_seed(seed)\n    np.random.seed(seed)\n    \n\n\n# Variables\nn_inputs = X_train.shape[1]\nn_hidden1 = 15\nn_hidden2 = 5\nn_outputs = 2\n\n# Reset the tensorboard graph\nreset_graph()\n\n\n# Placeholders\nX = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\ny = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n\n\n# Structure of the Neural Network\nwith tf.name_scope(\"dnn\"):\n    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n                             activation=tf.nn.relu)\n    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n                             activation=tf.nn.relu)\n    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n\n# Cost Function\nwith tf.name_scope(\"loss\"):\n    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n                                                     logits=logits) # Difference from logits and actual y values\n    loss = tf.reduce_mean(xentropy) # Get the average of the loss for each instance.\n\n# Gradient Descent\nlearning_rate = 0.01\n\nwith tf.name_scope(\"train\"):\n    optimization = tf.train.GradientDescentOptimizer(learning_rate) # Determine the level of steps in gradient descent process.\n    training_op = optimization.minimize(loss) # Get the training set with parameters that obtain the minimum loss.\n\n# Evaluation\nwith tf.name_scope(\"eval\"):\n    correct = tf.nn.in_top_k(logits, y, 1) # Did the highest score of logit is equivalent to the actual value(returns booleans)\n    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32)) # We want the mean of the loss for every instance.\n    \n\n\n# Init and Saver\ninit = tf.global_variables_initializer() # This variable initializes all variables.\nsaver = tf.train.Saver() # Saves the training set \n\n\namnt_epochs = 5\nbatch_size = 100\n\nwith tf.Session() as sess:\n    init.run()\n    \n    for epoch in range(amnt_epochs):\n        epoch_loss = 0\n        i=0\n        while i < len(X_train):\n            start = i\n            end = i+batch_size\n            batch_x = np.array(X_train[start:end])\n            batch_y = np.array(y_train[start:end])\n\n            _, c = sess.run([training_op, loss], feed_dict={X: batch_x,\n                                              y: batch_y})\n            epoch_loss += c\n            i+=batch_size\n        acc_train = accuracy.eval(feed_dict={X: batch_x, y: batch_y})\n        acc_test = accuracy.eval(feed_dict={X: X_test, y:y_test})\n\n        print(epoch+1, 'Train accuracy: ', acc_train, 'Test accuracy: ', acc_test, 'Loss: ', epoch_loss)","execution_count":13,"outputs":[{"output_type":"stream","text":"1 Train accuracy:  0.943662 Test accuracy:  0.94817793 Loss:  9414.440069729462\n2 Train accuracy:  0.92957747 Test accuracy:  0.9491348 Loss:  8859.027611339465\n3 Train accuracy:  0.92957747 Test accuracy:  0.94954914 Loss:  8765.774554077536\n4 Train accuracy:  0.92957747 Test accuracy:  0.9497248 Loss:  8713.440914921463\n5 Train accuracy:  0.92957747 Test accuracy:  0.94989604 Loss:  8682.39115839079\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby(['accepted']).count()","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"          Amount Requested  Debt-To-Income Ratio  Risk_Score  \\\naccepted                                                       \n0                  8992576               8992576     8992576   \n1                   864852                864852      864852   \n\n          Employment Length_10+ years  Employment Length_2 years  \\\naccepted                                                           \n0                             8992576                    8992576   \n1                              864852                     864852   \n\n          Employment Length_3 years  Employment Length_4 years  \\\naccepted                                                         \n0                           8992576                    8992576   \n1                            864852                     864852   \n\n          Employment Length_5 years  Employment Length_6 years  \\\naccepted                                                         \n0                           8992576                    8992576   \n1                            864852                     864852   \n\n          Employment Length_7 years  ...  State_SD  State_TN  State_TX  \\\naccepted                             ...                                 \n0                           8992576  ...   8992576   8992576   8992576   \n1                            864852  ...    864852    864852    864852   \n\n          State_UT  State_VA  State_VT  State_WA  State_WI  State_WV  State_WY  \naccepted                                                                        \n0          8992576   8992576   8992576   8992576   8992576   8992576   8992576  \n1           864852    864852    864852    864852    864852    864852    864852  \n\n[2 rows x 63 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Amount Requested</th>\n      <th>Debt-To-Income Ratio</th>\n      <th>Risk_Score</th>\n      <th>Employment Length_10+ years</th>\n      <th>Employment Length_2 years</th>\n      <th>Employment Length_3 years</th>\n      <th>Employment Length_4 years</th>\n      <th>Employment Length_5 years</th>\n      <th>Employment Length_6 years</th>\n      <th>Employment Length_7 years</th>\n      <th>...</th>\n      <th>State_SD</th>\n      <th>State_TN</th>\n      <th>State_TX</th>\n      <th>State_UT</th>\n      <th>State_VA</th>\n      <th>State_VT</th>\n      <th>State_WA</th>\n      <th>State_WI</th>\n      <th>State_WV</th>\n      <th>State_WY</th>\n    </tr>\n    <tr>\n      <th>accepted</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>...</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n      <td>8992576</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>...</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n      <td>864852</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows Ã— 63 columns</p>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}